
# ğŸ§  ML Evaluator Dashboard | Tablero de EvaluaciÃ³n de Modelos de ML

## ğŸ¯ Project Objective | Objetivo del proyecto

Construir una herramienta interactiva que permita comparar y evaluar mÃºltiples modelos de Machine Learning con mÃ©tricas avanzadas y visualizaciones explicativas.

Build an interactive tool to compare and evaluate multiple Machine Learning models using advanced metrics and explanatory visualizations.

---

## ğŸš€ Features | Funcionalidades

âœ… ComparaciÃ³n de modelos (Random Forest, XGBoost, SVM, etc.)  
âœ… EvaluaciÃ³n con validaciÃ³n cruzada y mÃ©tricas como Accuracy, F1, AUC y Log-loss  
âœ… VisualizaciÃ³n de resultados en dashboard interactivo con Streamlit  
âœ… AnÃ¡lisis de importancia de variables y explicabilidad con SHAP  

âœ… Model comparison (Random Forest, XGBoost, SVM, etc.)  
âœ… Evaluation using cross-validation and metrics like Accuracy, F1, AUC, and Log-loss  
âœ… Results visualization via Streamlit interactive dashboard  
âœ… Feature importance analysis and explainability with SHAP

---

## ğŸ§± Stack TecnolÃ³gico | Tech Stack

- Python 3.9+
- Streamlit
- Scikit-learn
- XGBoost
- SHAP
- Matplotlib / Seaborn
- Pandas / NumPy

---

## ğŸ–¼ Demo

Puedes ver la demo aquÃ­: [ML Evaluator App](https://mlmodelevaluatornz.streamlit.app)

You can try the demo here: [ML Evaluator App](https://mlmodelevaluatornz.streamlit.app)

---

## ğŸ CÃ³mo ejecutar localmente | How to Run Locally

```bash
# Clonar el repositorio / Clone repository
git clone https://github.com/tu_usuario/portfolio.git
cd portfolio/ml_model_evaluator

# Crear entorno virtual / Create virtual environment
python -m venv .venv
source .venv/bin/activate  # o `.\.venv\Scriptsctivate` en Windows

# Instalar dependencias / Install dependencies
pip install -r requirements.txt

# Ejecutar la aplicaciÃ³n / Run the app
streamlit run src/app.py
```

---

## ğŸ§ª Estructura del Proyecto | Project Structure

```
ml_model_evaluator/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ marketing_campaign.csv
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ final_model_pipeline.pkl
â”‚   â””â”€â”€ final_model_best_params.json
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ eda_marketing_campaign.ipynb
â”‚   â””â”€â”€ model_report.ipynb
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ classification_report.csv
â”‚   â”œâ”€â”€ comparison_results.csv
â”‚   â”œâ”€â”€ model_evaluation_results.csv
â”‚   â”œâ”€â”€ shap_bar_plot.png
â”‚   â”œâ”€â”€ shap_summary_plot.png
â”‚   â”œâ”€â”€ roc_curves.png
â”‚   â””â”€â”€ conf_matrix.png
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ evaluation_utils.py
â”‚   â”œâ”€â”€ evaluator.py
â”‚   â”œâ”€â”€ explain.py
â”‚   â”œâ”€â”€ model_factory.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ tuning.py
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š Resultados esperados | Expected Outputs

- GrÃ¡ficos comparativos de mÃ©tricas entre modelos base y optimizados
- Explicaciones SHAP para interpretabilidad
- Rankings de importancia de variables
- Matrices de confusiÃ³n y curvas ROC/AUC

---

## ğŸ“Œ Notas finales | Final Notes

Este proyecto fue creado como parte de un portafolio de ciencia de datos.

This project is part of a Data Science portfolio.
